[
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "Paper Overview",
    "section": "",
    "text": "Predicting how diseases like malaria spread is a big challenge, especially as climate change shifts global temperature patterns. A key part of this prediction involves understanding how temperature affects different biological traits of mosquitoes and the parasites they carry — for example, how quickly mosquitoes develop (MDR), how fast the malaria parasite matures inside them (PDR), or how often mosquitoes bite humans. These temperature-sensitive traits are used to calculate something called the basic reproduction number, or R_0, which tells us how easily a disease can spread in a population.\nThe problem is that reliable data for these traits — especially at different temperatures — is limited and often noisy. Instead of drawing a single best-fit curve through the data, the paper we are following uses a Bayesian approach with a technique called Markov Chain Monte Carlo (MCMC) to model the uncertainty. This method creates a range of possible trait curves, not just one, and gives us a clearer picture of how confident we are in the estimates.\nIn our project, we recreate part of this modeling framework using publicly available data from the VectorByte platform. We focus on two or three key traits: mosquito development rate (MDR), parasite development rate (PDR), and possibly mosquito bite rate. Using Bayesian methods and JAGS, we fit temperature-performance curves for these traits, visualize their uncertainty, and show how this uncertainty can impact larger models of disease transmission like R_0."
  },
  {
    "objectID": "introduction.html#abstract",
    "href": "introduction.html#abstract",
    "title": "Paper Overview",
    "section": "",
    "text": "Predicting how diseases like malaria spread is a big challenge, especially as climate change shifts global temperature patterns. A key part of this prediction involves understanding how temperature affects different biological traits of mosquitoes and the parasites they carry — for example, how quickly mosquitoes develop (MDR), how fast the malaria parasite matures inside them (PDR), or how often mosquitoes bite humans. These temperature-sensitive traits are used to calculate something called the basic reproduction number, or R_0, which tells us how easily a disease can spread in a population.\nThe problem is that reliable data for these traits — especially at different temperatures — is limited and often noisy. Instead of drawing a single best-fit curve through the data, the paper we are following uses a Bayesian approach with a technique called Markov Chain Monte Carlo (MCMC) to model the uncertainty. This method creates a range of possible trait curves, not just one, and gives us a clearer picture of how confident we are in the estimates.\nIn our project, we recreate part of this modeling framework using publicly available data from the VectorByte platform. We focus on two or three key traits: mosquito development rate (MDR), parasite development rate (PDR), and possibly mosquito bite rate. Using Bayesian methods and JAGS, we fit temperature-performance curves for these traits, visualize their uncertainty, and show how this uncertainty can impact larger models of disease transmission like R_0."
  },
  {
    "objectID": "introduction.html#data-collection",
    "href": "introduction.html#data-collection",
    "title": "Paper Overview",
    "section": "1. Data Collection",
    "text": "1. Data Collection\nThe authors assembled two types of datasets:\n\nMain data: Laboratory data under constant temperature, focused on Anopheles gambiae and Plasmodium falciparum. These data were only available for a few traits like mosquito development rate (MDR), egg-to-adult survival (pEA), and adult mosquito mortality (\\(\\mu\\)).\nPrior data: A broader set that included similar traits from related species and less controlled experiments. This dataset was used to construct informative priors in the Bayesian models.\n\n\nPlasmodium Falciparum\n\n\n\n\n\n\n\n\nAnopheles Gambiae"
  },
  {
    "objectID": "introduction.html#modeling-thermal-responses",
    "href": "introduction.html#modeling-thermal-responses",
    "title": "Paper Overview",
    "section": "2. Modeling Thermal Responses",
    "text": "2. Modeling Thermal Responses\nEach biological trait (component of the basic reproductive number, R₀) was modeled as a unimodal response to temperature, typically hump-shaped.\nTwo types of thermal performance functions were used:\n\nBrière Model (asymmetric, for traits like MDR): \\[\nf(T) = a \\cdot T \\cdot (T - T_0) \\cdot \\sqrt{T_m - T}\n\\]\nQuadratic Model (symmetric, for other traits): \\[\nf(T) = -a \\cdot (T - T_{opt})^2 + b\n\\]\n\nChoice of function was based on the biological properties of each trait."
  },
  {
    "objectID": "introduction.html#likelihoods-and-constraints",
    "href": "introduction.html#likelihoods-and-constraints",
    "title": "Paper Overview",
    "section": "3. Likelihoods and Constraints",
    "text": "3. Likelihoods and Constraints\n\nMost traits used a truncated normal likelihood, which ensures outputs are biologically feasible\nFor probability traits (like vector competence or survival), the authors used a binomial likelihood when raw counts were available.\nAll values were constrained within biologically meaningful ranges. For example, traits expressed as probabilities were constrained to [0, 1]."
  },
  {
    "objectID": "introduction.html#bayesian-inference-workflow",
    "href": "introduction.html#bayesian-inference-workflow",
    "title": "Paper Overview",
    "section": "4. Bayesian Inference Workflow",
    "text": "4. Bayesian Inference Workflow\nEach trait was modeled individually with the following steps:\n\nDefine the likelihood using the selected functional form (Brière or quadratic).\nAssign priors:\n\nStart with uninformative priors (flat/diffuse).\nLater use informative priors derived from the prior dataset and expert opinion.\n\nRun MCMC in JAGS to sample from the posterior distribution of parameters:\n\nBrière: a, T₀, Tₘ, σ\n\nGenerate fitted curves using the posterior draws:\n\nMedian curve (posterior mean)\n95% credible interval envelope"
  },
  {
    "objectID": "methods.html",
    "href": "methods.html",
    "title": "Materials",
    "section": "",
    "text": "Here we introduce the materials!\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(readxl)\nlibrary(here)\n\nhere() starts at /Users/yusiyao/Desktop/VT/STAT_4664_Stochastic/final\n\nlibrary(rjags)\n\nLoading required package: coda\nLinked to JAGS 4.3.2\nLoaded modules: basemod,bugs\n\nlibrary(coda)\n\n# Load and prepare the data\ntrait_data &lt;- read_excel(here(\"data\", \"the_one_we_need.xlsx\"))\ndf &lt;- trait_data %&gt;%\n  select(T = Interactor1Temp, trait = OriginalTraitValue) %&gt;%\n  drop_na()\n\n# JAGS model (same as before)\nbriere_model &lt;- \"\nmodel {\n  for (i in 1:N) {\n    trait[i] ~ dnorm(mu[i], tau)\n    mu[i] &lt;- c * T[i] * (T[i] - T0) * sqrt(Tm - T[i])\n  }\n  c ~ dgamma(1, 10)\n  T0 ~ dunif(0, 24)\n  Tm ~ dunif(25, 45)\n  sigma ~ dunif(0, 10)\n  tau &lt;- pow(sigma, -2)\n}\n\"\n\n# Prepare data for JAGS\njags_data &lt;- list(\n  T = df$T,\n  trait = df$trait,\n  N = nrow(df)\n)\n\ninits &lt;- function() {\n  list(c = runif(1, 0, 1), T0 = runif(1, 0, 20), Tm = runif(1, 25, 45), sigma = runif(1, 0, 1))\n}\n\nparams &lt;- c(\"c\", \"T0\", \"Tm\", \"sigma\")\n\nmodel &lt;- jags.model(textConnection(briere_model), data = jags_data, inits = inits, n.chains = 3)\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 8\n   Unobserved stochastic nodes: 4\n   Total graph size: 50\n\nInitializing model\n\nupdate(model, 1000)\nsamples &lt;- coda.samples(model, variable.names = params, n.iter = 5000)\n\n# Extract MCMC draws\nsamples_df &lt;- as.data.frame(do.call(rbind, samples))\n\n# Temperature sequence\ntemp_seq &lt;- seq(min(df$T) - 2, max(df$T) + 5, length.out = 200)\n\n# Calculate predicted values from posterior draws\npred_matrix &lt;- apply(samples_df[sample(1:nrow(samples_df), 1000), c(\"c\", \"T0\", \"Tm\")], 1, function(pars) {\n  c_val &lt;- pars[1]\n  T0_val &lt;- pars[2]\n  Tm_val &lt;- pars[3]\n  ifelse(\n    temp_seq &gt; T0_val & temp_seq &lt; Tm_val,\n    c_val * temp_seq * (temp_seq - T0_val) * sqrt(pmax(Tm_val - temp_seq, 0)),\n    0\n  )\n})\n\n# Transpose so each row = temp, each column = sample\npred_matrix &lt;- t(pred_matrix)\n\n# Summarize by quantiles\npred_df &lt;- data.frame(\n  temp = temp_seq,\n  mean = apply(pred_matrix, 1, mean),\n  lower = apply(pred_matrix, 1, quantile, 0.025),\n  upper = apply(pred_matrix, 1, quantile, 0.975)\n)\n\nggplot(df, aes(x = T, y = trait)) +\n  geom_point(size = 2, alpha = 0.7) +\n  geom_ribbon(data = pred_df, aes(x = temp, ymin = lower, ymax = upper),\n              inherit.aes = FALSE, fill = \"lightblue\", alpha = 0.4) +\n  geom_line(data = pred_df, aes(x = temp, y = mean),\n            inherit.aes = FALSE, color = \"blue\", linewidth = 1.2) +\n  labs(\n    title = \"Mosquito Development Rate (MDR) with 95% Credible Interval\",\n    x = \"Temperature (°C)\",\n    y = \"Trait Value\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nlibrary(ggplot2)\nlibrary(rjags)\nlibrary(coda)\n\n# JAGS model using Brière function\nbriere_model &lt;- \"\nmodel {\n  for (i in 1:N) {\n    trait[i] ~ dnorm(mu[i], tau)\n    mu[i] &lt;- c * T[i] * (T[i] - T0) * sqrt(Tm - T[i])\n  }\n  c ~ dgamma(1, 10)\n  T0 ~ dunif(0, 24)\n  Tm ~ dunif(25, 45)\n  sigma ~ dunif(0, 10)\n  tau &lt;- pow(sigma, -2)\n}\n\"\n\n# Prepare data for JAGS\njags_data &lt;- list(\n  T = df$T,\n  trait = df$trait,\n  N = nrow(df)\n)\n\n# Initial values and parameters\ninits &lt;- function() {\n  list(c = runif(1, 0, 1), T0 = runif(1, 0, 20), Tm = runif(1, 25, 45), sigma = runif(1, 0, 1))\n}\nparams &lt;- c(\"c\", \"T0\", \"Tm\", \"sigma\")\n\n# Run model\nmodel &lt;- jags.model(textConnection(briere_model), data = jags_data, inits = inits, n.chains = 3)\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 8\n   Unobserved stochastic nodes: 4\n   Total graph size: 50\n\nInitializing model\n\nupdate(model, 1000)\nsamples &lt;- coda.samples(model, variable.names = params, n.iter = 5000)\n\n# Posterior draws\nsamples_df &lt;- as.data.frame(do.call(rbind, samples))\n\n# Predictive temperature range\ntemp_seq &lt;- seq(min(df$T) - 2, max(df$T) + 5, length.out = 200)\n\n# Predict Brière curve for each posterior draw\npred_matrix &lt;- apply(samples_df[sample(1:nrow(samples_df), 1000), c(\"c\", \"T0\", \"Tm\")], 1, function(pars) {\n  c_val &lt;- pars[1]\n  T0_val &lt;- pars[2]\n  Tm_val &lt;- pars[3]\n  ifelse(\n    temp_seq &gt; T0_val & temp_seq &lt; Tm_val,\n    c_val * temp_seq * (temp_seq - T0_val) * sqrt(pmax(Tm_val - temp_seq, 0)),\n    0\n  )\n})\n\n# Summarize predictions\npred_df &lt;- data.frame(\n  temp = temp_seq,\n  mean = rowMeans(pred_matrix),\n  lower = apply(pred_matrix, 1, quantile, 0.025),\n  upper = apply(pred_matrix, 1, quantile, 0.975)\n)\n\n# Plot\nggplot(df, aes(x = T, y = trait)) +\n  geom_point(size = 2, alpha = 0.8) +\n  geom_ribbon(data = pred_df, aes(x = temp, ymin = lower, ymax = upper),\n              inherit.aes = FALSE, fill = \"lightblue\", alpha = 0.4) +\n  geom_line(data = pred_df, aes(x = temp, y = mean),\n            inherit.aes = FALSE, color = \"blue\", linewidth = 1.2) +\n  labs(\n    title = \"Mosquito Development Rate (MDR) with 95% Credible Interval\",\n    x = \"Temperature (°C)\",\n    y = \"MDR\"\n  ) +\n  theme_minimal()"
  },
  {
    "objectID": "team.html",
    "href": "team.html",
    "title": "Basics",
    "section": "",
    "text": "Here we introduce basic functionality of the package!"
  },
  {
    "objectID": "overview.html",
    "href": "overview.html",
    "title": "What Is This Paper About?",
    "section": "",
    "text": "What Is This Paper About?\nAt its core, this paper tries to better understand how temperature affects the transmission of malaria, a disease caused by a parasite and spread by mosquitoes. More specifically, it looks at how different biological traits like, how fast mosquitoes grow or how quickly parasites develop, change depending on temperature.\nThese temperature-sensitive traits are key parts of a formula called \\(R_0\\), which is the basic reproduction number. In simple terms, \\(R_0\\) tells us how easily a disease can spread in a population. If \\(R_0\\) is high, an outbreak can happen. If it’s low, the disease dies out.\nBut to build this \\(R_0\\) model, the authors first need to estimate how these traits behave across temperatures. And that’s where the challenge begins.\n\n\nThe Big Obstacle\nOne of the biggest hurdles in this study is data scarcity. For many of the temperature-sensitive traits—like mosquito development rate (MDR) or parasite development rate (PDR)—the researchers had access to only about 8 to 12 usable data points in this example. That’s barely enough to fit a meaningful curve, especially if the data is spread out across temperatures or varies in quality.\nSo, why is the data so limited?\nExperimental constraints in lab settings. Since malaria is caused by a parasite (Plasmodium falciparum) that lives inside mosquitoes (Anopheles gambiae), studying the full transmission cycle requires infecting the mosquitoes. But under lab conditions, researchers cannot simply feed infected mosquitoes with their own blood to continue experiments, that would pose serious biohazard and ethical issues. This makes it extremely difficult to collect controlled, high-quality data for infected mosquitoes, especially across multiple temperatures.\nBeyond that, additional limitations include:\n\nEthical regulations around working with human-infectious diseases.\nTechnical difficulty of maintaining mosquitoes and parasites at constant temperatures in controlled environments.\nCost and time involved in conducting these studies, especially with biological replication.\n\nAs a result, the authors had to rely on a patchwork of data:\n\nSome traits came from direct lab studies on An. gambiae and P. falciparum.\nOthers had to be pulled from related mosquito or parasite species, or from less controlled studies, just to have enough data to work with.\n\n\n\nThe Solution: Bayesian Inference + MCMC\nTo deal with the limited and messy data, Prof.Johnson and her team used Bayesian inference, a statistical approach that is especially powerful when data is sparse or uncertain. Instead of trying to force-fit a single best curve through a handful of points, the Bayesian method treats the unknown curve parameters as random variables and estimates their entire probability distribution.\nThis is where MCMC (Markov Chain Monte Carlo) comes in. MCMC is a tool that lets you simulate samples from complicated distributions, like the posterior distribution of trait curves in this study. In simpler terms, it helps us generate many possible curves that are consistent with the data we do have—along with a sense of how confident we can be in each one.\nSo rather than returning a single line through the data, Johnson’s model gives you:\n\nA mean curve (the best guess)\nPlus a 95% credible interval (a range where the “true” curve likely falls).\n\nThis uncertainty is crucial. Because the biological data is so limited, we cannot pretend we know the exact trait-temperature relationship. But by using a Bayesian framework, the authors can at least show what’s plausible, based on both the data and prior biological knowledge.\nIn our project, we adopt this same logic. Using the real (limited) data, we apply a Bayesian curve-fitting approach to recreate key trait-temperature plots from the paper, starting with MDR and PDR."
  },
  {
    "objectID": "mcmc.html#bayesian-inference",
    "href": "mcmc.html#bayesian-inference",
    "title": "MCMC Tutorial",
    "section": "Bayesian Inference",
    "text": "Bayesian Inference\nBayesian inference provides a principled way to update our beliefs in light of data. It does so by combining a prior distribution \\(\\pi(q)\\), which encodes what we already believe, with a likelihood \\(\\pi(D \\mid q)\\), which represents how the data relate to the parameters. Together, they form the posterior:\n\\(\\pi(q \\mid D) \\propto \\pi(D \\mid q) \\, \\pi(q)\\)\nThis posterior captures everything we know about the parameters after observing data. As the speaker in the referenced talk put it:\n“These two things together with some data we get a posterior distribution and the posterior distribution captures all the information in our system. It’s a wonderfully kind of elegant theoretical property…”\nBut here’s the catch:\n“…the reality is that we can’t work with a posterior distribution. A high-dimensional probability distribution is a kind of meaningless thing. It’s this abstraction that we can’t interact with.”\nSo, how do we extract useful insights?\n\nFrom Posteriors to Expectations\nIn Bayesian inference, once we have our model and some data, the goal is to compute the posterior distribution, which combines our prior beliefs and the information from the data. This is usually written as:\n\\(\\pi(q \\mid D) \\propto \\pi(D \\mid q) \\pi(q)\\)\nHere, q represents all the unknown quantities we are trying to learn. These could be parameters like growth rates, optimal temperatures, or bite rate. The space of all possible values that q could take is what we call the parameter space. In simple models, this space might be one or two dimensional. In more realistic models—like those describing mosquito traits and parasite development—it can easily become 10, 20, or even hundreds of dimensions.\nNow, suppose we want to estimate something from this posterior—say, the average value of one trait or the probability that it exceeds a certain threshold. In Bayesian statistics, this means we need to compute expectations, which take the form:\n\\(\\mathbb{E}_{\\pi}[f] = \\int dq \\, \\pi(q \\mid D) f(q)\\)\nThis is the central computation in Bayesian inference. But computing such integrals extremely hard in high dimensions because it does not just evaluate the integrand, it aggregates it over volumns.\nImagine covering a 1D space (a line) with intervals.\n\n\n\n\n\nIn 2D, covering a square requires 9 tiles—one in the center and 8 around.\n\n\n\n\n\nIn 3D, a cube is surrounded by 26 others.\n\n\n\n\n\nAs dimensions increase, this “surrounding” effect grows rapidly. The volume of the space explodes outward, and the small region near the peak of our distribution (where we expect to learn the most) becomes a tiny fraction of the whole space.\nThis is a core problem. Even if we know where the posterior is highest (its “peak”), most of the probability mass lies in a weird, thin shell around it, not directly at the center. And trying to integrate over this complex shape with regular grid-based methods (like the ones we learn in calculus) just isn’t feasible when the dimension goes beyond 3 or 4.\nSo, to actually compute expectations in high-dimensional parameter spaces, we need smarter tools. This is where Monte Carlo method step in, and eventually, Markov Chain Monte Carlo come into play."
  },
  {
    "objectID": "mcmc.html#monte-carlo-sampling-instead-of-solving",
    "href": "mcmc.html#monte-carlo-sampling-instead-of-solving",
    "title": "MCMC Tutorial",
    "section": "Monte Carlo: Sampling Instead of Solving",
    "text": "Monte Carlo: Sampling Instead of Solving\nSo far, we’ve learned that Bayesian inference boils down to computing an expectation: an integral over a high-dimensional parameter space. But as we saw, volume in high dimensions behaves oddly—making that integral nearly impossible to solve with traditional methods like grid search or numeric quadrature. The regions that matter most are small and hard to find.\nThis is where Monte Carlo methods step in. Rather than trying to compute the integral directly, Monte Carlo flips the problem: it draws random samples from the posterior distribution, and then approximates the expectation by averaging over those samples.\nThink of it like this: imagine trying to understand how students perform in a large university, but instead of surveying every single student, you randomly sample students from the most populated classes—because that’s where most of the action happens. Similarly, Monte Carlo sampling draws points from areas where the posterior distribution places the most weight. These areas, known as the typical set, are where most of the useful information lives. So instead of wasting effort sampling from the outskirts, Monte Carlo methods focus where it counts.\nMathematically, if we draw N independent samples \\(q_1, q_2, \\ldots, q_N\\) from the posterior \\(\\pi(q \\mid D)\\), the Monte Carlo estimator is simply:\n\\[\\frac{1}{N} \\sum_{n=1}^{N} f(q_n) \\sim \\mathcal{N}\\left(\\mathbb{E}[f], \\frac{\\mathrm{Var}[f]}{N} \\right)\\]\nBut there’s a challenge.\nSampling from a complex posterior is not straightforward. In order to draw the sample, we need to know where the typical set is. They are the same problem. All I have done is recasting the problem in a different manner. The typical set is a thin, hard-to-find slice of the full space. If our samples miss it, then the estimate is wrong. Monte Carlo tells us what to do, but not how to do it.\nAnd that’s where Markov chains come in."
  },
  {
    "objectID": "mcmc.html#markov-chains-stepping-through-the-posterior",
    "href": "mcmc.html#markov-chains-stepping-through-the-posterior",
    "title": "MCMC Tutorial",
    "section": "Markov Chains: Stepping Through the Posterior",
    "text": "Markov Chains: Stepping Through the Posterior\nInstead of sampling independently, we construct a sequence of correlated samples. We start at one point \\(q{\\prime}\\) in parameter space and generate the next point q using a transition rule, or what’s formally called a Markov transition kernel, written as:\n\\[T(q \\mid q{\\prime})\\]\nThis transition rule defines the probability of jumping from one state to another. We repeat this process—step by step—generating a chain of points that slowly “wanders” through the parameter space. You can think of it as taking a random walk.\nThis alone doesn’t help much. But here’s the key insight: if we engineer this transition kernel \\(T(q \\mid q{\\prime})\\) to preserve the posterior distribution, then something powerful happens.\nFormally, the stationary distribution of the chain becomes our target posterior:\n\\[\\pi(q) = \\int \\pi(q{\\prime}) \\, T(q \\mid q{\\prime}) \\, dq{\\prime}\\]\nThis equation says: if we draw enough samples using a well-designed Markov transition, the resulting distribution of the chain will match the posterior we care about. Even though the individual samples are correlated, they still reflect the true structure of the target distribution.\n\n\n\nMarkov transition preserves target distribution that natually concentrates towards the typical set\n\n\nSo, Markov chains let us do the impossible: sample from complex posteriors without needing a full map of the space. Instead, we let the chain guide us, one probabilistic step at a time.\n\nWe combine this idea with Monte Carlo, and it leads us to the powerhouse technique known as Markov Chain Monte Carlo (MCMC)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Final Project",
    "section": "",
    "text": "In this project, we aim to recreate a specific component of the analysis from Johnson et al. (2015), which investigates how temperature influences the transmission potential of malaria through its effect on various mosquito and parasite traits. Rather than reproducing the full reproductive number \\(R_0\\), we focus on a single temperature-sensitive trait — parasite development rate (PDR) and mosquito mortality — to explore how Bayesian inference can quantify uncertainty in that trait’s temperature response. The data for this analysis come from the VectorByte platform, which provides curated temperature-dependent trait data relevant to vector-borne diseases. By implementing and visualizing this subset of the model, we illustrate the impact of trait uncertainty on broader disease transmission dynamics, using methods and approaches aligned with those described in the original paper."
  },
  {
    "objectID": "conclusions.html",
    "href": "conclusions.html",
    "title": "Conclusions",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "conclusions.html#quarto",
    "href": "conclusions.html#quarto",
    "title": "Conclusions",
    "section": "",
    "text": "Quarto enables you to weave together content and executable code into a finished document. To learn more about Quarto see https://quarto.org."
  },
  {
    "objectID": "conclusions.html#running-code",
    "href": "conclusions.html#running-code",
    "title": "Conclusions",
    "section": "Running Code",
    "text": "Running Code\nWhen you click the Render button a document will be generated that includes both content and the output of embedded code. You can embed code like this:\n\n1 + 1\n\n[1] 2\n\n\nYou can add options to executable code like this\n\n\n[1] 4\n\n\nThe echo: false option disables the printing of code (only output is displayed)."
  }
]
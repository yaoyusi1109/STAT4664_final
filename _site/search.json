[
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "Final Project",
    "section": "",
    "text": "Predicting how diseases like malaria spread is a big challenge, especially as climate change shifts global temperature patterns. A key part of this prediction involves understanding how temperature affects different biological traits of mosquitoes and the parasites they carry — for example, how quickly mosquitoes develop (MDR), how fast the malaria parasite matures inside them (PDR), or how often mosquitoes bite humans. These temperature-sensitive traits are used to calculate something called the basic reproduction number, or R_0, which tells us how easily a disease can spread in a population.\nThe problem is that reliable data for these traits — especially at different temperatures — is limited and often noisy. Instead of drawing a single best-fit curve through the data, the paper we are following uses a Bayesian approach with a technique called Markov Chain Monte Carlo (MCMC) to model the uncertainty. This method creates a range of possible trait curves, not just one, and gives us a clearer picture of how confident we are in the estimates."
  },
  {
    "objectID": "introduction.html#abstract",
    "href": "introduction.html#abstract",
    "title": "Final Project",
    "section": "",
    "text": "Predicting how diseases like malaria spread is a big challenge, especially as climate change shifts global temperature patterns. A key part of this prediction involves understanding how temperature affects different biological traits of mosquitoes and the parasites they carry — for example, how quickly mosquitoes develop (MDR), how fast the malaria parasite matures inside them (PDR), or how often mosquitoes bite humans. These temperature-sensitive traits are used to calculate something called the basic reproduction number, or R_0, which tells us how easily a disease can spread in a population.\nThe problem is that reliable data for these traits — especially at different temperatures — is limited and often noisy. Instead of drawing a single best-fit curve through the data, the paper we are following uses a Bayesian approach with a technique called Markov Chain Monte Carlo (MCMC) to model the uncertainty. This method creates a range of possible trait curves, not just one, and gives us a clearer picture of how confident we are in the estimates."
  },
  {
    "objectID": "introduction.html#data-collection",
    "href": "introduction.html#data-collection",
    "title": "Final Project",
    "section": "1. Data Collection",
    "text": "1. Data Collection\nThe authors assembled two types of datasets:\n\nMain data: Laboratory data under constant temperature, focused on Anopheles gambiae and Plasmodium falciparum. These data were only available for three traits mosquito development rate (MDR), egg-to-adult survival (pEA), and adult mosquito mortality (\\(\\mu\\)). For other traits ideal data, the researcher used data from related species.\nPrior data: A broader set that included similar traits from related species and less controlled experiments. This dataset was used to construct informative priors in the Bayesian models.\n\n\nPlasmodium Falciparum (parasite)\n\n\n\n\n\n\n\n\nAnopheles Gambiae (mosquitoes)"
  },
  {
    "objectID": "introduction.html#bayesian-inference-workflow",
    "href": "introduction.html#bayesian-inference-workflow",
    "title": "Final Project",
    "section": "2. Bayesian Inference Workflow",
    "text": "2. Bayesian Inference Workflow\nIn this study, Bayesian inference is used to estimate the thermal responses of individual biological traits that drive malaria transmission. The goal is to determine how key mosquito and parasite traits vary with temperature, and ultimately, how this affects the basic reproduction number R_0.\nThe Bayesian approach proceeds in three major steps:\n\n1. Define a Likelihood Function\nFor each biological trait (e.g., mosquito development rate, parasite development rate), a thermal response curve—either a Brière (asymmetric) or quadratic (symmetric) function—is chosen to describe how the trait changes with temperature. The observed data are then modeled as arising from a truncated normal distribution centered around this function, with lower truncation at zero to reflect biological constraints (e.g., traits like development rate cannot be negative). For traits that are probabilities (e.g., vector competence), a binomial likelihood is used if raw count data are available.\n\n\n2. Specify Prior Distributions\nPrior distributions are selected for the parameters of the thermal response functions, including biologically motivated temperature bounds (e.g., 0°C–45°C). Initially, uninformative priors are used to allow the data to dominate the inference. Later, informative priors are constructed by fitting the model to a broader prior dataset, and then summarizing the resulting posterior estimates to inform the main analysis. This two-step prior construction helps stabilize the inference when main data are sparse or noisy.\n\n\n3. Sample from the Posterior via MCMC\nOnce likelihood and priors are specified, inference proceeds by generating posterior samples using Markov Chain Monte Carlo (MCMC) techniques such as JAGS. These samples represent plausible combinations of parameter values given both the prior knowledge and the observed data. From these, the posterior mean curves and credible intervals (e.g., 95% HPD bands) are derived to quantify uncertainty.\n\n2.1 Likelihood Definition\nWe will use the parasite deveolpment rate (PDR) as an illustration of the general workflow. According to the paper, researchers assumed that trait values vary nonlinearly with temperature and exhibit a unimodal, asymmetric pattern. This biological response was modeled using a Brière function, a common choice for temperature-dependent traits that increase sharply, peak at an intermediate temperature, and decline at high temperatures:\n\\[f(T) = c \\cdot T \\cdot (T - T_0) \\cdot \\sqrt{T_m - T}, \\quad \\text{for } T_0 &lt; T &lt; T_m\\] Here: - T is the temperature (°C), - \\(T_0\\) is the lower developmental threshold, - \\(T_m\\) is the upper thermal limit, - c is a scaling constant.\nTo connect this deterministic curve to the observed data, we assume that each observed PDR value \\(Y_i\\) (e.g., from a lab experiment) is a noisy realization of the theoretical value \\(f(T_i)\\), where \\(T_i\\) is the temperature at which the observation was recorded. This noise is modeled using a truncated normal distribution, ensuring all simulated values remain biologically meaningful (i.e., non-negative):\n\\[Y_i \\sim \\text{Normal}\\left(f(T_i), \\sigma^2\\right) \\quad \\text{truncated at } 0\\]\n\n\n2.2 Prior Distribution\nIn the Bayesian framework, prior distributions express our beliefs about the parameters before seeing the data. For the parasite development rate (PDR), the model includes four parameters: the lower thermal limit \\(T_0\\), upper thermal limit \\(T_m\\), a scaling constant c, and a standard deviation \\(\\sigma\\) representing observation noise.\nBased on biological constraints and prior studies (as described in the paper and Appendix A.3), the following priors were chosen:\n\n\\(T_0\\) (lower bound of development): We assume development does not occur below roughly 5°C. So we used a truncated normal prior: \\(T_0 \\sim \\text{Normal}(12.3, 2.5^2) \\text{ truncated at } [0, ]\\)\n\n\n\n\n\n\n\n\n\n\n\n\\(T_m\\) (upper limit of development): Mosquitoes and malaria parasites typically die or stop developing near 40°C. We used: \\(T_m \\sim \\text{Normal}(35, 1.0^2) \\text{ truncated at } [T_0, 45]\\)\n\n\n\n\n\n\n\n\n\n\n\nc (scaling parameter of the Brière function): The scaling constant c controls the overall height of the thermal curve. Since it must be positive and is hard to predict precisely, we used a weakly informative gamma prior: \\(c \\sim \\text{Gamma}(2, 40000)\\)\n\n\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\nI honetly don’t know why we choose this but just based on the graph this puts most of the prior mass near zero but allows a long right tail.\n\n\\(\\sigma\\) (standard deviation of noise): We assume the variability in the observations is positive but small. So: \\(\\sigma \\sim \\text{Uniform}(0, 1)\\)\n\n\n\n\n\n\n\n\n\n\n\n\n2.3 Posterior Sampling via MCMC\nMathematically, Bayes’ theorem tells us: \\(\\text{Posterior} \\propto \\text{Likelihood} \\times \\text{Prior}\\) But in practice, this product cannot be simplified or integrated analytically, especially when our model is nonlinear (like the Brière function for PDR) and high-dimensional.\nThis is where Markov Chain Monte Carlo (MCMC) comes in as we mentioned before.\nThe Tool: JAGS\n\nlibrary(rjags)\n\nLoading required package: coda\n\n\nLinked to JAGS 4.3.2\n\n\nLoaded modules: basemod,bugs\n\n\nTo estimate the posterior, we used JAGS (Just Another Gibbs Sampler). It allows us to simulate draws from the posterior distribution, even when the model is complex and has truncated or nonlinear components.\nIn our case, we used MCMC to sample from the joint posterior of the four parameters:\\(T_0, T_m, c, \\sigma\\)\nThe Process:\nWe ran 3 parallel chains to ensure convergence from different starting points. - Each chain ran for 5000 iterations, with a 1000-iteration burn-in period to discard the early “warm-up” samples. - In total, this gave us 12,000 posterior samples (3 chains × 4000 samples each).\nThe JAGS output gave us: - Posterior means (best estimate for each parameter) - 95% credible intervals (uncertainty) - Diagnostics like effective sample size and trace plots\nThese samples allow us to: - Estimate the PDR curve across temperature - Quantify uncertainty (via credible bands) - Propagate this uncertainty into the final R_0 calculation # Inference in Bayesian framework\nUsually proceed in three steps.\n\nA likelihood is defined for each type of data.\nAppropriate prior distributions are determined.\nSamples from the posterior distribution of hte parameters via MCMC.\n\n\nlibrary(rjags)\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ stringr   1.5.1\n✔ forcats   1.0.0     ✔ tibble    3.2.1\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(here)\n\n# Load data\nmosquitoes1 &lt;- readxl::read_excel(here(\"data\", \"the_one_we_need.xlsx\"))\n\nNew names:\n• `` -&gt; `...10`\n\n# Filter and prepare PDR data\npdr_data &lt;- mosquitoes1 %&gt;%\n  filter(OriginalTraitName == \"EIP (extrinsic incubation period)\",\n         !is.na(Interactor1Temp),\n         !is.na(OriginalTraitValue)) %&gt;%\n  mutate(\n    temp = as.numeric(Interactor1Temp),\n    pdr = 1 / as.numeric(OriginalTraitValue)\n  ) %&gt;%\n  arrange(temp)\n\n# Define JAGS model string\njags_model &lt;- \"\nmodel {\n  for (i in 1:N) {\n    pdr[i] ~ dnorm(mu[i], tau)\n    mu[i] &lt;- c * temp[i] * (temp[i] - T0) * sqrt(Tm - temp[i])\n  }\n\n  # Priors (informative)\n  T0 ~ dnorm(14, 1 / (3.5^2))\n  tm ~ dgamma(14.7, 3.1)\n  Tm &lt;- 31 + tm\n  c ~ dexp(100)\n\n  # Likelihood precision\n  tau &lt;- pow(sigma, -2)\n  sigma ~ dunif(0, 10)\n}\n\"\n\n# Bundle data for JAGS\ndata_jags &lt;- list(\n  temp = pdr_data$temp,\n  pdr = pdr_data$pdr,\n  N = nrow(pdr_data)\n)\n\n# Initial values\ninits &lt;- function() {\n  list(T0 = 14, tm = 5, c = 0.001, sigma = 1)\n}\n\n# Parameters to monitor\nparams &lt;- c(\"T0\", \"Tm\", \"c\", \"sigma\")\n\n# Run the JAGS model\nmodel &lt;- jags.model(textConnection(jags_model), data = data_jags, inits = inits, n.chains = 3)\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 8\n   Unobserved stochastic nodes: 4\n   Total graph size: 56\n\nInitializing model\n\nupdate(model, 1000)  # Burn-in\nsamples &lt;- rjags::coda.samples(model, variable.names = params, n.iter = 4000)\n\n# Summarize posterior\nsummary(samples)\n\n\nIterations = 2001:6000\nThinning interval = 1 \nNumber of chains = 3 \nSample size per chain = 4000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n           Mean        SD  Naive SE Time-series SE\nT0    1.006e+01 2.214e+00 2.021e-02      1.042e-01\nTm    3.565e+01 1.190e+00 1.086e-02      1.663e-02\nc     5.598e-05 1.745e-05 1.593e-07      7.802e-07\nsigma 6.775e-03 2.710e-03 2.474e-05      7.373e-05\n\n2. Quantiles for each variable:\n\n           2.5%       25%       50%       75%     97.5%\nT0    5.267e+00 8.653e+00 1.023e+01 1.162e+01 1.389e+01\nTm    3.361e+01 3.480e+01 3.555e+01 3.641e+01 3.821e+01\nc     3.228e-05 4.384e-05 5.291e-05 6.410e-05 9.868e-05\nsigma 3.567e-03 4.964e-03 6.150e-03 7.846e-03 1.358e-02\n\n\n\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(coda)\nlibrary(tidyr)\n\n# Step 1: Extract summary statistics\nsummary_stats &lt;- summary(samples)\npost_means &lt;- summary_stats$statistics[, \"Mean\"]\nT0 &lt;- post_means[\"T0\"]\nTm &lt;- post_means[\"Tm\"]\nc_param &lt;- post_means[\"c\"]\n\n# Step 2: Define the Brière function\nbriere &lt;- function(T, T0, Tm, c) {\n  out &lt;- c * T * (T - T0) * sqrt(Tm - T)\n  out[T &lt;= T0 | T &gt;= Tm] &lt;- 0\n  return(out)\n}\n\n# Step 3: Generate prediction ribbon from posterior draws\nposterior_df &lt;- do.call(rbind, samples)\ntemps &lt;- seq(5, 45, length.out = 200)\npred_matrix &lt;- apply(posterior_df, 1, function(row) {\n  briere(temps, row[\"T0\"], row[\"Tm\"], row[\"c\"])\n})\npred_summary &lt;- data.frame(\n  temp = temps,\n  mean = rowMeans(pred_matrix),\n  lwr = apply(pred_matrix, 1, quantile, 0.025),\n  upr = apply(pred_matrix, 1, quantile, 0.975)\n)\n\n# Step 4: Clean observed data\npdr_data_clean &lt;- mosquitoes1 %&gt;%\n  filter(OriginalTraitName == \"parasite development rate (1/EIP)\") %&gt;%\n  mutate(\n    temp = as.numeric(Interactor1Temp),\n    PDR = as.numeric(OriginalTraitValue),\n    species_marker = case_when(\n      Interactor1Species == \"gambiae\" ~ \"An. gambiae\",\n      grepl(\"falciparum\", OriginalTraitDef, ignore.case = TRUE) ~ \"Other anopheline\",\n      TRUE ~ \"Other\"\n    ),\n    shape = case_when(\n      species_marker == \"An. gambiae\" ~ 19,  # solid circle\n      species_marker == \"Other anopheline\" ~ 3,  # plus\n      TRUE ~ 8  # star\n    )\n  ) %&gt;%\n  filter(!is.na(temp), !is.na(PDR))\n\n# Step 5: Plot\nggplot() +\n  geom_ribbon(data = pred_summary, aes(x = temp, ymin = lwr, ymax = upr), alpha = 0.2, linetype = \"dashed\") +\n  geom_line(data = pred_summary, aes(x = temp, y = mean), size = 1) +\n  geom_point(data = pdr_data_clean, aes(x = temp, y = PDR, shape = species_marker), size = 2) +\n  scale_shape_manual(values = c(\"An. gambiae\" = 19, \"Other anopheline\" = 3, \"Other\" = 8)) +\n  labs(\n    x = \"Temperature (°C)\",\n    y = \"Parasite development rate, PDR\",\n    shape = \"Species\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nHere we finally reproduced the posterior for PDR: )"
  },
  {
    "objectID": "methods.html",
    "href": "methods.html",
    "title": "Trait Modeling Expansion to 4 other traits",
    "section": "",
    "text": "To replicate the trait-temperature modeling from Johnson et al., we applied Bayesian inference to multiple biological traits. Each trait was modeled individually using a biologically appropriate function (either Brière or quadratic), with parameters inferred via MCMC using JAGS. We began with a detailed model for juvenile mosquito survival to validate our workflow and then applied the same framework to other traits: mosquito development rate (MDR), oocyst prevalence, and oocyst intensity."
  },
  {
    "objectID": "methods.html#trait-1-survival-rate-quadratic-model",
    "href": "methods.html#trait-1-survival-rate-quadratic-model",
    "title": "Trait Modeling Expansion to 4 other traits",
    "section": "Trait 1: Survival Rate (Quadratic Model)",
    "text": "Trait 1: Survival Rate (Quadratic Model)\n\n\nhere() starts at /Users/yusiyao/Desktop/VT/STAT_4664_Stochastic/final\n\n\nThis code block isolates only the rows related to the “survival” trait for Anopheles gambiae in the juvenile stage. This is the specific data subset most relevant to thermal survival modeling for the malaria vector. We also convert survival percentages into proportions for modeling (0 to 1 scale).\n\n# Filter for 'survival' trait, remove missing temps or values\nsurvival_data &lt;- trait_data %&gt;%\n  filter(\n    OriginalTraitName == \"survival\",\n    !is.na(OriginalTraitValue),\n    !is.na(Interactor1Temp),\n    Interactor1Genus == \"Anopheles\",\n    Interactor1Species == \"gambiae\",\n    Interactor1Stage == \"juvenile\"\n  ) %&gt;%\n  mutate(\n    temp = Interactor1Temp,\n    survival_rate = OriginalTraitValue / 100  # Convert percent to proportion\n  )\n\n\nExploratory Plot\nTo begin exploring the relationship between temperature and mosquito survival, we plotted survival proportion (Proportion Surviving) against environmental temperature (Temperature (°C)) for juvenile Anopheles gambiae.\n\n\n\n\n\n\n\n\n\nNotice that we only have 10 usable data points, but even with limited data it supports the fact that mosquitos have a ideal temperature range\n\n\nFitting the quadratic model\n\n# Fit a quadratic model to survival data\nquad_model &lt;- lm(survival_rate ~ poly(temp, 2, raw = TRUE), data = survival_data)\n\n# Generate predicted values\ntemp_seq &lt;- seq(min(survival_data$temp), max(survival_data$temp), length.out = 200)\npred_df &lt;- data.frame(temp = temp_seq)\npred_df$predicted &lt;- predict(quad_model, newdata = pred_df)\n\n\nggplot(survival_data, aes(x = temp, y = survival_rate)) +\n  geom_point(size = 2.5, color = \"#1f77b4\") +\n  geom_line(data = pred_df, aes(x = temp, y = predicted), color = \"darkred\", size = 1) +\n  labs(\n    title = \"Quadratic Fit: Survival Rate vs Temperature\",\n    x = \"Temperature (°C)\",\n    y = \"Proportion Surviving\"\n  ) +\n  theme_minimal()\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n\n\n\nThe survival data for Anopheles gambiae (juvenile stage) shows a clear unimodal pattern when plotted against temperature. Despite the limited number of data points, fitting a quadratic curve allows us to visualize this thermal response reliably.\n\n\nJAGS Bayesian Model (Quadratic)\nJAGS is a method that allows you to define a probablistic model in a simple syntax. This uses MCMC to sample from the posterior distributuion of the model parameters given just our data\n\n# Select and rename columns for clarity\njags_data &lt;- list(\n  N = nrow(survival_data),\n  y = survival_data$survival_rate,\n  temp = survival_data$temp\n)\nmodel_string &lt;- \"\nmodel {\n  for (i in 1:N) {\n    # Likelihood: trait value follows normal distribution around a quadratic curve\n    mu[i] &lt;- a - b * pow(temp[i] - Topt, 2)\n    y[i] ~ dnorm(mu[i], tau)\n  }\n\n  # Priors\n  a ~ dnorm(0.85, 400)           # Prior mean of 0.85 with sd = 0.05 → precision = 1/(0.05)^2 = 400\n  b ~ dgamma(2.0, 1.0)           # Constrains curve to open downward\n  Topt ~ dunif(15, 35)           # Prior range for optimal temperature\n  sigma ~ dunif(0, 1)            # Prior on residual error\n  tau &lt;- pow(sigma, -2)          # Precision for the normal likelihood\n}\n\"\n\nThis JAGS model captures the unimodal thermal response of mosquito survival using a quadratic function, where survival is modeled as peaking at an optimal temperature (Topt) and symmetrically declining at higher and lower temperatures. We place a strong prior on the peak survival rate (a ~ dnorm(0.85, 400)), reflecting biological expectations that juvenile Anopheles gambiae mosquitoes exhibit maximum survival around 85% under optimal thermal conditions. The curvature parameter b is modeled with a gamma prior to enforce a positive value, ensuring the quadratic curve opens downward. A uniform prior is used for Topt within a biologically reasonable range (15–35°C), and a loose prior on the residual standard deviation sigma allows for flexibility in error estimation. By incorporating these priors, the model more faithfully represents prior biological understanding and helps stabilize inference given the small sample size.\n\nlibrary(rjags)\n\nLoading required package: coda\n\n\nLinked to JAGS 4.3.2\n\n\nLoaded modules: basemod,bugs\n\n# Create and compile the model\nmodel &lt;- jags.model(\n  textConnection(model_string),\n  data = jags_data,\n  n.chains = 3,\n  n.adapt = 1000\n)\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 10\n   Unobserved stochastic nodes: 4\n   Total graph size: 74\n\nInitializing model\n\n# Burn-in\nupdate(model, 2000)\n\n# Sample from the posterior\nsamples &lt;- coda.samples(model,\n                        variable.names = c(\"a\", \"Topt\", \"b\", \"sigma\"),\n                        n.iter = 5000)\n\n# Convert to matrix for plotting/analysis\nsamples_df &lt;- as.data.frame(do.call(rbind, samples))\n\n\n# Plot trace for diagnostics\nlibrary(bayesplot)\n\nThis is bayesplot version 1.11.1\n\n\n- Online documentation and vignettes at mc-stan.org/bayesplot\n\n\n- bayesplot theme set to bayesplot::theme_default()\n\n\n   * Does _not_ affect other ggplot2 plots\n\n\n   * See ?bayesplot_theme_set for details on theme setting\n\nmcmc_trace(samples)\n\n\n\n\n\n\n\n# Posterior summary\nsummary(samples)\n\n\nIterations = 3001:8000\nThinning interval = 1 \nNumber of chains = 3 \nSample size per chain = 5000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n           Mean       SD  Naive SE Time-series SE\nTopt  24.510847 0.444173 3.627e-03      6.123e-03\na      0.820073 0.039737 3.245e-04      5.156e-04\nb      0.009961 0.001252 1.022e-05      1.943e-05\nsigma  0.137580 0.047285 3.861e-04      9.935e-04\n\n2. Quantiles for each variable:\n\n           2.5%       25%       50%      75%    97.5%\nTopt  23.631055 24.269202 24.524556 24.76563 25.34096\na      0.745167  0.792957  0.819064  0.84607  0.89988\nb      0.007543  0.009171  0.009935  0.01073  0.01251\nsigma  0.079300  0.106510  0.127967  0.15681  0.25819\n\n\nWe ran a 3-chain, 5000-iteration MCMC using JAGS. The trace plots for each parameter suggest good mixing and convergence. All chains overlap well, with no signs of divergence or poor exploration. This confirms the stability of the posterior estimates under our quadratic model.\nPosterior distributions for the model parameters suggest that the optimal temperature for survival is approximately 24.5°C, with a credible interval from 23.5°C to 25.4°C. The maximum survival rate is estimated to be around 77%. The parameter b, which controls the curve’s sharpness, is estimated near 0.0092. The residual error term (sigma) is low, indicating a tight fit despite limited data.\n\nposterior predictive curves\n\n# Step 1: Generate predictions from posterior samples\ntemp_seq &lt;- seq(min(survival_data$temp), max(survival_data$temp), length.out = 200)\n\n# Compute mu = a - b*(temp - Topt)^2 for each sample\nposterior_predictions &lt;- sapply(temp_seq, function(t) {\n  samples_df$a - samples_df$b * (t - samples_df$Topt)^2\n})\n\n# Summarize predictions\npred_summary &lt;- data.frame(\n  temp = temp_seq,\n  median = apply(posterior_predictions, 2, median),\n  lower = apply(posterior_predictions, 2, quantile, 0.025),\n  upper = apply(posterior_predictions, 2, quantile, 0.975)\n)\n# Preview the posterior prediction summary\nhead(pred_summary)\n\n      temp     median       lower     upper\n1 16.00000 0.09465132 -0.13460406 0.3248791\n2 16.09045 0.10993927 -0.11537379 0.3360083\n3 16.18090 0.12506491 -0.09617179 0.3473070\n4 16.27136 0.13996617 -0.07703946 0.3583867\n5 16.36181 0.15477683 -0.05817878 0.3689567\n6 16.45226 0.16937064 -0.03954669 0.3799977\n\nDT::datatable(pred_summary, options = list(pageLength = 10))\n\n\n\n\n\n\n# Step 2: Plot posterior median + 95% credible interval ribbon\nggplot() +\n  geom_point(data = survival_data, aes(x = temp, y = survival_rate), size = 2.5, color = \"#1f77b4\") +\n  geom_line(data = pred_summary, aes(x = temp, y = median), color = \"darkred\", size = 1.2) +\n  geom_ribbon(data = pred_summary, aes(x = temp, ymin = lower, ymax = upper), \n              fill = \"darkred\", alpha = 0.2) +\n  labs(\n    title = \"Posterior Predictive Fit: Survival Rate vs Temperature\",\n    x = \"Temperature (°C)\",\n    y = \"Proportion Surviving\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nTo evaluate model fit and uncertainty, we generated a posterior predictive curve for juvenile Anopheles gambiae survival across temperatures using JAGS. The figure above shows the median posterior estimate of survival (dark red curve) and a 95% credible interval (shaded band), overlaid on observed survival proportions (blue points).\nDespite having only 10 observed data points, the Bayesian model captures a clear unimodal pattern, consistent with biological expectations: survival peaks around an optimal temperature near 24.5°C and decreases at both cooler and hotter extremes. The credible interval reflects the model’s uncertainty, widening where data is sparse or noisy.\nThis result confirms that even with limited data, incorporating uncertainty through Bayesian inference provides more interpretable and realistic predictions — especially critical for epidemiological models like R0, which are sensitive to small changes in trait estimates.\n\n\nKey takeaways\nHaving validated our modeling workflow using the survival data, we now extend the same Bayesian framework to additional traits that contribute to malaria transmission. These traits vary in biological behavior and data quality, requiring different modeling choices for likelihoods, priors, and transformations. Below, we demonstrate this process for the rest of the traits"
  },
  {
    "objectID": "methods.html#trait-2-mosquito-development-rate-mdr-brière-model",
    "href": "methods.html#trait-2-mosquito-development-rate-mdr-brière-model",
    "title": "Trait Modeling Expansion to 4 other traits",
    "section": "Trait 2: Mosquito Development Rate (MDR) — Brière Model",
    "text": "Trait 2: Mosquito Development Rate (MDR) — Brière Model\n\n# Load required libraries\nlibrary(tidyverse)\nlibrary(readxl)\nlibrary(here)\n\n# Filter for Development Time (Trait)\ndev_data &lt;- trait_data %&gt;%\n  filter(\n    OriginalTraitName == \"development time\",\n    !is.na(OriginalTraitValue),\n    !is.na(Interactor1Temp),\n    Interactor1Genus == \"Anopheles\",\n    Interactor1Species == \"gambiae\",\n    Interactor1Stage == \"juvenile\"\n  ) %&gt;%\n  mutate(\n    temp = Interactor1Temp,\n    development_time = as.numeric(OriginalTraitValue),\n    mdr = 1 / development_time  # Invert to get development rate\n  ) %&gt;%\n  drop_na(mdr)\n\n# Visualize\nggplot(dev_data, aes(x = temp, y = mdr)) +\n  geom_point(color = \"#2ca02c\", size = 2) +\n  labs(title = \"MDR vs Temperature (from Development Time)\",\n       x = \"Temperature (°C)\", y = \"MDR (1 / days)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\nmdr_data &lt;- dev_data %&gt;%\n  filter(!is.na(mdr), is.finite(mdr), mdr &gt;= 0) %&gt;%\n  rename(rate = mdr)\n\n\nJAGS and Briere function\n\nbriere &lt;- function(T, c, T0, Tm) {\n  ifelse(T &gt; T0 & T &lt; Tm, c * T * (T - T0) * sqrt(Tm - T), 0)\n}\n\njags_data_mdr &lt;- list(N = nrow(dev_data), y = dev_data$rate, temp = dev_data$temp)\n\nWarning: Unknown or uninitialised column: `rate`.\n\nbriere_model_mdr &lt;- \"\nmodel {\n  for (i in 1:N) {\n    valid[i] &lt;- step(temp[i] - T0) * step(Tm - temp[i])\n    mu[i] &lt;- valid[i] * c * temp[i] * (temp[i] - T0) * sqrt(Tm - temp[i] + 1e-6)\n    y[i] ~ dnorm(mu[i], tau)\n  }\n  c ~ dgamma(1.0, 1.0)\n  T0 ~ dunif(0, 20)\n  Tm ~ dunif(25, 45)\n  sigma ~ dunif(0, 1)\n  tau &lt;- pow(sigma, -2)\n}\n\"\nmodel_mdr &lt;- jags.model(textConnection(briere_model_mdr), data = jags_data_mdr, n.chains = 3, n.adapt = 1000)\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 0\n   Unobserved stochastic nodes: 14\n   Total graph size: 114\n\nInitializing model\n\nupdate(model_mdr, 2000)\nsamples_mdr &lt;- coda.samples(model_mdr, c(\"c\", \"T0\", \"Tm\", \"sigma\"), 5000)\nsamples_df_mdr &lt;- as.data.frame(do.call(rbind, samples_mdr))\n\n\nbriere_model_mdr &lt;- \"\nmodel {\n  for (i in 1:N) {\n    # Stability: avoid sqrt(0) by adding a small constant (1e-6)\n    valid[i] &lt;- step(temp[i] - T0) * step(Tm - temp[i])\n    mu[i] &lt;- valid[i] * c * temp[i] * (temp[i] - T0) * sqrt(Tm - temp[i] + 1e-6)\n    y[i] ~ dnorm(mu[i], tau)\n  }\n\n  # Priors\n  c ~ dgamma(1.0, 1.0)       # Positive rate scaling\n  T0 ~ dunif(0, 20)          # Lower thermal limit\n  Tm ~ dunif(25, 45)         # Upper thermal limit\n  sigma ~ dunif(0, 1)        # Standard deviation\n  tau &lt;- pow(sigma, -2)\n}\n\"\n\n\nlibrary(rjags)\n\nmodel_mdr &lt;- jags.model(\n  textConnection(briere_model_mdr),\n  data = jags_data_mdr,\n  n.chains = 3,\n  n.adapt = 1000\n)\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 0\n   Unobserved stochastic nodes: 14\n   Total graph size: 114\n\nInitializing model\n\nupdate(model_mdr, 2000)\n\nsamples_mdr &lt;- coda.samples(\n  model_mdr,\n  variable.names = c(\"c\", \"T0\", \"Tm\", \"sigma\"),\n  n.iter = 5000\n)\n\nsamples_df_mdr &lt;- as.data.frame(do.call(rbind, samples_mdr))\n\n\nsamples_mdr &lt;- coda.samples(\n  model_mdr,\n  variable.names = c(\"c\", \"T0\", \"Tm\", \"sigma\"),\n  n.iter = 5000\n)\n\n# Combine all chains into one data frame\nsamples_df_mdr &lt;- as.data.frame(do.call(rbind, samples_mdr))\n\n\n# Trace plots\nlibrary(bayesplot)\nmcmc_trace(samples_mdr)\n\n\n\n\n\n\n\n# Posterior summary statistics\nsummary(samples_mdr)\n\n\nIterations = 7001:12000\nThinning interval = 1 \nNumber of chains = 3 \nSample size per chain = 5000 \n\n1. Empirical mean and standard deviation for each variable,\n   plus standard error of the mean:\n\n         Mean     SD Naive SE Time-series SE\nT0     9.9592 5.7669 0.047087       0.047085\nTm    34.9496 5.7796 0.047190       0.048948\nc      1.0007 1.0108 0.008253       0.008228\nsigma  0.4983 0.2893 0.002362       0.002363\n\n2. Quantiles for each variable:\n\n          2.5%     25%     50%    75%   97.5%\nT0     0.49215  4.9154  9.9791 14.934 19.4688\nTm    25.49132 29.9341 34.9046 39.944 44.5217\nc      0.02550  0.2849  0.6915  1.393  3.6801\nsigma  0.02448  0.2476  0.4960  0.751  0.9766\n\n\nThe trace plots for the Brière model parameters provide insight into the stability and uncertainty of our MCMC sampling. While the chains for the coefficient ( c ) and the error term ( ) appear moderately stable, those for the lower (( T_0 )) and upper (( T_m )) thermal limits show wide, noisy fluctuations across iterations and chains. This lack of convergence suggests the model is unable to tightly constrain these parameters — likely due to limited data coverage at the temperature extremes.\nSuch behavior is expected in biological systems with sparse or uneven data. Nevertheless, the sampling behavior indicates that the model is exploring plausible regions of parameter space rather than overfitting. To mitigate this uncertainty, future work could incorporate weakly informative priors based on laboratory observations, or increase the number of MCMC iterations to improve convergence. Despite the noise, posterior predictions remain biologically reasonable, with credible intervals capturing uncertainty appropriately.\n\n# Sequence of temperature values for prediction\ntemp_seq &lt;- seq(min(mdr_data$temp), max(mdr_data$temp), length.out = 200)\n\n# Predict MDR values using Brière function and sampled parameters\nposterior_predictions &lt;- sapply(temp_seq, function(t) {\n  with(samples_df_mdr, {\n    ifelse(t &gt; T0 & t &lt; Tm, c * t * (t - T0) * sqrt(Tm - t), 0)\n  })\n})\n\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\nWarning in sqrt(Tm - t): NaNs produced\n\n# Summarize predictions\npred_summary &lt;- data.frame(\n  temp = temp_seq,\n  median = apply(posterior_predictions, 2, median),\n  lower = apply(posterior_predictions, 2, quantile, 0.025),\n  upper = apply(posterior_predictions, 2, quantile, 0.975)\n)\n\n\nggplot() +\n  geom_point(data = mdr_data, aes(x = temp, y = rate), size = 2, color = \"#2ca02c\") +\n  geom_line(data = pred_summary, aes(x = temp, y = median), color = \"darkorange\", size = 1.2) +\n  geom_ribbon(data = pred_summary, aes(x = temp, ymin = lower, ymax = upper), \n              fill = \"darkorange\", alpha = 0.25) +\n  labs(\n    title = \"Posterior Predictive Fit: MDR vs Temperature\",\n    x = \"Temperature (°C)\",\n    y = \"Mosquito Development Rate (1 / days)\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThis plot shows the posterior predictive fit for Mosquito Development Rate (MDR) as a function of temperature. The orange curve represents the median predicted rate based on posterior samples, while the shaded region is the 95% credible interval. The fitted curve increases and then flattens, capturing the nonlinear thermal response. However, the y-axis scaling suggests a plotting error — predicted values appear exaggerated, likely due to a bug in how the Brière predictions were generated or summarized. This should be corrected by confirming unit consistency and checking for vector recycling or incorrect exponentiation."
  },
  {
    "objectID": "methods.html#trait-3-oocyst-prevalence-and-intensity",
    "href": "methods.html#trait-3-oocyst-prevalence-and-intensity",
    "title": "Trait Modeling Expansion to 4 other traits",
    "section": "Trait 3: Oocyst prevalence and intensity",
    "text": "Trait 3: Oocyst prevalence and intensity\n\n# Load original dataset\nlibrary(here)\nlibrary(readr)\ntrait_data &lt;- read_csv(\n  here(\"data\", \"vec_traits_download_Wed Apr 30 2025 19_32_46 GMT-0400 (Eastern Daylight Time).csv\")\n)\n\nRows: 108 Columns: 53\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (41): OriginalID, OriginalTraitName, OriginalTraitDef, OriginalTraitUnit...\ndbl (12): Id, DatasetID, OriginalTraitValue, OriginalErrorPos, OriginalError...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n# Oocyst Prevalence\noocyst_prev_data &lt;- trait_data %&gt;%\n  filter(\n    OriginalTraitName == \"oocyst prevalence\",\n    !is.na(OriginalTraitValue),\n    !is.na(Interactor1Temp)\n  ) %&gt;%\n  mutate(\n    temp = Interactor1Temp,\n    prevalence = OriginalTraitValue / 100\n  ) %&gt;%\n  filter(prevalence &gt;= 0 & prevalence &lt;= 1)\n\n# Oocyst Intensity\noocyst_int_data &lt;- trait_data %&gt;%\n  filter(\n    OriginalTraitName == \"oocyst intensity\",\n    !is.na(OriginalTraitValue),\n    !is.na(Interactor1Temp)\n  ) %&gt;%\n  mutate(\n    temp = Interactor1Temp,\n    intensity = as.numeric(OriginalTraitValue)\n  ) %&gt;%\n  drop_na(intensity)\n\n\n# Prevalence plot\nggplot(oocyst_prev_data, aes(x = temp, y = prevalence)) +\n  geom_point(color = \"#d62728\", size = 2) +\n  labs(title = \"Oocyst Prevalence vs Temperature\",\n       x = \"Temperature (°C)\", y = \"Prevalence (Proportion)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n# Intensity plot\nggplot(oocyst_int_data, aes(x = temp, y = intensity)) +\n  geom_point(color = \"#9467bd\", size = 2) +\n  labs(title = \"Oocyst Intensity vs Temperature\",\n       x = \"Temperature (°C)\", y = \"Intensity (Mean Count)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThe first scatterplot shows the raw data for oocyst prevalence across temperatures. Each point represents a measured proportion of mosquitoes carrying oocysts at a given environmental temperature. Most data points are clustered around 17°C and 19°C, indicating sparse thermal coverage and a need for cautious interpretation of model fits.\nThe second plot shows the raw data for oocyst intensity — the average number of oocysts per mosquito — as a function of temperature. Similar to prevalence, intensity data are concentrated around 17°C and 19°C. The limited range limits the resolution of the fitted curve, but it still supports some basic inference about thermal sensitivity.\n\njags_data_prev &lt;- list(\n  N = nrow(oocyst_prev_data),\n  y = oocyst_prev_data$prevalence,\n  temp = oocyst_prev_data$temp\n)\n\nmodel_string_prev &lt;- \"\nmodel {\n  for (i in 1:N) {\n    y[i] ~ dnorm(mu[i], tau)\n    mu[i] &lt;- a - b * pow(temp[i] - Topt, 2)\n  }\n\n  # Priors\n  a ~ dunif(0, 1)\n  b ~ dgamma(2.0, 1.0)\n  Topt ~ dunif(15, 35)\n  sigma ~ dunif(0, 1)\n  tau &lt;- pow(sigma, -2)\n}\n\"\n\n\nmodel_prev &lt;- jags.model(\n  textConnection(model_string_prev),\n  data = jags_data_prev,\n  n.chains = 3,\n  n.adapt = 1000\n)\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 46\n   Unobserved stochastic nodes: 4\n   Total graph size: 112\n\nInitializing model\n\nupdate(model_prev, 2000)\n\nsamples_prev &lt;- coda.samples(model_prev,\n                             variable.names = c(\"a\", \"Topt\", \"b\", \"sigma\"),\n                             n.iter = 5000)\n\nsamples_df_prev &lt;- as.data.frame(do.call(rbind, samples_prev))\n\n\ntemp_seq &lt;- seq(min(oocyst_prev_data$temp), max(oocyst_prev_data$temp), length.out = 200)\n\npred_prev &lt;- sapply(temp_seq, function(t) {\n  samples_df_prev$a - samples_df_prev$b * (t - samples_df_prev$Topt)^2\n})\n\npred_summary_prev &lt;- data.frame(\n  temp = temp_seq,\n  median = apply(pred_prev, 2, median),\n  lower = apply(pred_prev, 2, quantile, 0.025),\n  upper = apply(pred_prev, 2, quantile, 0.975)\n)\n\nggplot() +\n  geom_point(data = oocyst_prev_data, aes(x = temp, y = prevalence), size = 2, color = \"#d62728\") +\n  geom_line(data = pred_summary_prev, aes(x = temp, y = median), color = \"darkred\", size = 1.2) +\n  geom_ribbon(data = pred_summary_prev, aes(x = temp, ymin = lower, ymax = upper), fill = \"darkred\", alpha = 0.2) +\n  labs(title = \"Posterior Predictive Fit: Oocyst Prevalence\",\n       x = \"Temperature (°C)\", y = \"Prevalence (Proportion)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThis plot presents the posterior predictive distribution for oocyst prevalence. The dark red curve shows the median prediction from the quadratic JAGS model, while the shaded band is the 95% credible interval. The model captures a unimodal pattern peaking around 18°C, reflecting optimal transmission conditions under this trait. However, sparse data outside this narrow window limits generalizability.\n\n# Filter and prepare oocyst intensity data\nintensity_data &lt;- trait_data %&gt;%\n  filter(\n    OriginalTraitName == \"oocyst intensity\",\n    !is.na(OriginalTraitValue),\n    !is.na(Interactor1Temp),\n    Interactor1Genus == \"Anopheles\",\n    Interactor1Species == \"gambiae\"\n  ) %&gt;%\n  mutate(\n    temp = Interactor1Temp,\n    intensity = as.numeric(OriginalTraitValue)\n  ) %&gt;%\n  # Filter only values &gt; 0 for safe log-transform\n  filter(intensity &gt; 0) %&gt;%\n  mutate(log_intensity = log(intensity))\n\n# Check if any remaining NA/Inf values exist\nsummary(intensity_data$log_intensity)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0000  0.2801  0.8519  0.9155  1.3397  2.1972 \n\n# Log-transform response for modeling\nintensity_data &lt;- intensity_data %&gt;%\n  mutate(log_intensity = log(intensity))\n\n# Visualize data\nggplot(intensity_data, aes(x = temp, y = intensity)) +\n  geom_point(size = 2, color = \"#9467bd\") +\n  labs(\n    title = \"Oocyst Intensity vs Temperature\",\n    x = \"Temperature (°C)\",\n    y = \"Mean Oocyst Count\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThis plot presents the posterior predictive distribution for oocyst prevalence. The dark red curve shows the median prediction from the quadratic JAGS model, while the shaded band is the 95% credible interval. The model captures a unimodal pattern peaking around 18°C, reflecting optimal transmission conditions under this trait. However, sparse data outside this narrow window limits generalizability.\n\n# Define data list\njags_data_intensity &lt;- list(\n  N = nrow(intensity_data),\n  y = intensity_data$log_intensity,\n  temp = intensity_data$temp\n)\n\n\n# Quadratic log-normal model\n# JAGS model definition\nlognorm_model &lt;- \"\nmodel {\n  for (i in 1:N) {\n    mu[i] &lt;- a - b * pow(temp[i] - Topt, 2)\n    y[i] ~ dnorm(mu[i], tau)\n  }\n\n  # Priors\n  a ~ dnorm(0, 1.0)\n  b ~ dgamma(1.5, 1.0)\n  Topt ~ dunif(15, 35)\n  sigma ~ dunif(0, 2)\n  tau &lt;- pow(sigma, -2)\n}\n\"\n\n\nlibrary(rjags)\n\nmodel_intensity &lt;- jags.model(\n  textConnection(lognorm_model),\n  data = jags_data_intensity,\n  n.chains = 3,\n  n.adapt = 1000\n)\n\nCompiling model graph\n   Resolving undeclared variables\n   Allocating nodes\nGraph information:\n   Observed stochastic nodes: 6\n   Unobserved stochastic nodes: 4\n   Total graph size: 33\n\nInitializing model\n\nupdate(model_intensity, 2000)\n\nsamples_intensity &lt;- coda.samples(\n  model_intensity,\n  variable.names = c(\"a\", \"b\", \"Topt\", \"sigma\"),\n  n.iter = 5000\n)\n\nsamples_df_intensity &lt;- as.data.frame(do.call(rbind, samples_intensity))\n\n\n# Generate predictions on log scale, then exponentiate\ntemp_seq &lt;- seq(min(intensity_data$temp), max(intensity_data$temp), length.out = 200)\n\nposterior_predictions &lt;- sapply(temp_seq, function(t) {\n  exp(samples_df_intensity$a - samples_df_intensity$b * (t - samples_df_intensity$Topt)^2)\n})\n\n# Summarize predictions\npred_summary_intensity &lt;- data.frame(\n  temp = temp_seq,\n  median = apply(posterior_predictions, 2, median),\n  lower = apply(posterior_predictions, 2, quantile, 0.025),\n  upper = apply(posterior_predictions, 2, quantile, 0.975)\n)\n\n# Plot\nggplot() +\n  geom_point(data = intensity_data, aes(x = temp, y = intensity), size = 2.5, color = \"#9467bd\") +\n  geom_line(data = pred_summary_intensity, aes(x = temp, y = median), color = \"black\", size = 1.2) +\n  geom_ribbon(data = pred_summary_intensity, aes(x = temp, ymin = lower, ymax = upper),\n              fill = \"gray\", alpha = 0.3) +\n  labs(\n    title = \"Posterior Predictive Fit: Oocyst Intensity vs Temperature\",\n    x = \"Temperature (°C)\",\n    y = \"Mean Oocyst Count\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nHere, we visualize posterior predictions for oocyst intensity using a log-normal quadratic model. The black curve and gray ribbon show the median and 95% credible interval of predicted counts, respectively. Despite minimal data, the model finds a weak peak near 18.5°C, suggesting a preferred temperature for parasite proliferation, albeit with wide uncertainty.\n\n# Trace plots for oocyst prevalence model\nlibrary(bayesplot)\nmcmc_trace(samples_prev)\n\n\n\n\n\n\n\n# Trace plots for oocyst intensity model\nmcmc_trace(samples_intensity)\n\n\n\n\n\n\n\n\nThe first plot displays the MCMC sampling behavior for the four model parameters (Topt, a, b, sigma) in the oocyst prevalence model. All chains mix well and appear stationary, with no visible divergence. This indicates reliable posterior estimates for downstream inference.\nThe second trace plots for the oocyst intensity model demonstrate stable mixing across three chains. Parameters converge well, particularly Topt and sigma, although b and a exhibit higher variance. The results are sufficient for posterior prediction but would benefit from more temperature-diverse data to reduce uncertainty."
  },
  {
    "objectID": "team.html",
    "href": "team.html",
    "title": "Progress Report 1",
    "section": "",
    "text": "Yusi:\nPretty much everything\nRahulr:\nMethod Expansion and conclusion\n\nProgress Report 1\n\n\n\n\nProgress Report 2"
  },
  {
    "objectID": "overview.html",
    "href": "overview.html",
    "title": "What Is This Paper About?",
    "section": "",
    "text": "What Is This Paper About?\nAt its core, this paper tries to better understand how temperature affects the transmission of malaria, a disease caused by a parasite and spread by mosquitoes. More specifically, it looks at how different biological traits like, how fast mosquitoes grow or how quickly parasites develop, change depending on temperature.\nThese temperature-sensitive traits are key parts of a formula called \\(R_0\\), which is the basic reproduction number. In simple terms, \\(R_0\\) tells us how easily a disease can spread in a population. If \\(R_0\\) is high, an outbreak can happen. If it’s low, the disease dies out.\nThe most widely used formulation for malaria \\(R_0\\) (Diez 1993) defrived from the Ross-Macdonald Model (1952): \\[\nR_0 = \\sqrt{\\frac{M}{Nr} \\times \\frac{a^2 bc \\exp(-\\mu/\\text{PDR})}{\\mu}}\n\\]\n\n\n\n\n\n\n\n\n\n\n\nParameter\nDefinition\nPrior Species\nPrior Sources\nMain Species\nMain Sources\n\n\n\n\na\nbiting rate\nAedes albopictus\nCalado and Navarro-Silva (2002), Delatte et al. (2009)\nAn. pseudopunctipennis\nLardeux et al. (2008)\n\n\nMDR\nmosquito development rate\nAn. gambiae, An. quadrimaculatus, Aedes triseriatus, Aedes aegypti, An. superpictus\nJepson et al. (1947), Love and Whlechel (1957), Jalil (1972), Joshi et al. (1996), Briegel et al. (2001), Aytekin et al. (2009)\nAn. gambiae\nBayoh and Lindsay (2003)\n\n\npₑₐ\negg to adult survival\nAn. quadrimaculatus, Aedes triseriatus, Aedes albopictus\nLove and Whlechel (1957), Jalil (1972), Delatte et al. (2009)\nAn. gambiae\nBayoh and Lindsay (2003)\n\n\nEFD\nfecundity\nAedes aegypti\nJoshi et al. (1996)\nAedes albopictus\nCalado and Navarro-Silva (2002), Delatte et al. (2009)\n\n\nμ\nmosquito mortality rate\nAedes aegypti, An. superpictus\nJoshi et al. (1996), Aytekin et al. (2009), Costantini et al. (1996), Gary & Foster (2004), Impoinvil et al. (2007), Midega et al. (2007), Okech et al. (2003)\nAn. gambiae\nBayoh (2001)\n\n\nbc\nvector competence\nP. relictum in Culex quinquefasciatus\nLaPointe et al. (2010)\nP. vivax in An. quadrimaculatus\nStratman-Thomas (1940)\n\n\nPDR\nparasite development rate\nP. vivax in An. quadrimaculatus, P. falciparum in An. gambiae\nStratman-Thomas (1940), Cambournac (1942), Boyd (1949)\nP. falciparum in An. gambiae, An. culicifacies, An. stephensi, An. quadrimaculatus, An. atroparvus\nBoyd and Stratman-Thomas (1933), Knowles and Basu (1943), Siddons (1944), Shute and Maryon (1952), Vaughan et al. (1992), Eling et al. (2001)\n\n\n\n\nNote: EIP is the extrinsic incubation period of the parasite.\n\nAnd the expected mosquito density is given by: \\[\nM = \\frac{\\text{EFD} \\cdot p_{EA} \\cdot \\text{MDR}}{\\mu^2}\n\\]\nBut to build this \\(R_0\\) model, the authors first need to estimate how these traits behave across temperatures. And that’s where the challenge begins.\n\n\nThe Big Obstacle\nOne of the biggest hurdles in this study is data scarcity. For many of the temperature-sensitive traits—like mosquito development rate (MDR) or parasite development rate (PDR)—the researchers had access to only about 8 to 12 usable data points in this example. That’s barely enough to fit a meaningful curve, especially if the data is spread out across temperatures or varies in quality.\nSo, why is the data so limited?\nExperimental constraints in lab settings. Since malaria is caused by a parasite (Plasmodium falciparum) that lives inside mosquitoes (Anopheles gambiae), studying the full transmission cycle requires infecting the mosquitoes. But under lab conditions, researchers cannot simply feed infected mosquitoes with their own blood to continue experiments, that would pose serious biohazard and ethical issues. This makes it extremely difficult to collect controlled, high-quality data for infected mosquitoes, especially across multiple temperatures.\nBeyond that, additional limitations include:\n\nEthical regulations around working with human-infectious diseases.\nTechnical difficulty of maintaining mosquitoes and parasites at constant temperatures in controlled environments.\nCost and time involved in conducting these studies, especially with biological replication.\n\nAs a result, the authors had to rely on a patchwork of data:\n\nSome traits came from direct lab studies on An. gambiae and P. falciparum.\nOthers had to be pulled from related mosquito or parasite species, or from less controlled studies, just to have enough data to work with.\n\n\n\nThe Solution: Bayesian Inference + MCMC\nTo deal with the limited and messy data, Prof.Johnson and her team used Bayesian inference, a statistical approach that is especially powerful when data is sparse or uncertain. Instead of trying to force-fit a single best curve through a handful of points, the Bayesian method treats the unknown curve parameters as random variables and estimates their entire probability distribution.\nThis is where MCMC (Markov Chain Monte Carlo) comes in. MCMC is a tool that lets you simulate samples from complicated distributions, like the posterior distribution of trait curves in this study. In simpler terms, it helps us generate many possible curves that are consistent with the data we do have—along with a sense of how confident we can be in each one.\nSo rather than returning a single line through the data, Johnson’s model gives you:\n\nA mean curve (the best guess)\nPlus a 95% credible interval (a range where the “true” curve likely falls).\n\nThis uncertainty is crucial. Because the biological data is so limited, we cannot pretend we know the exact trait-temperature relationship. But by using a Bayesian framework, the authors can at least show what’s plausible, based on both the data and prior biological knowledge.\nIn our project, we adopt this same logic. Using the real (limited) data, we apply a Bayesian curve-fitting approach to recreate key trait-temperature plots from the paper, starting with MDR and PDR."
  },
  {
    "objectID": "mcmc.html#bayesian-inference",
    "href": "mcmc.html#bayesian-inference",
    "title": "MCMC Tutorial",
    "section": "Bayesian Inference",
    "text": "Bayesian Inference\nBayesian inference provides a principled way to update our beliefs in light of data. It does so by combining a prior distribution \\(\\pi(q)\\), which encodes what we already believe, with a likelihood \\(\\pi(D \\mid q)\\), which represents how the data relate to the parameters. Together, they form the posterior:\n\\(\\pi(q \\mid D) \\propto \\pi(D \\mid q) \\, \\pi(q)\\)\nThis posterior captures everything we know about the parameters after observing data. As the speaker in the referenced talk put it:\n“These two things together with some data we get a posterior distribution and the posterior distribution captures all the information in our system. It’s a wonderfully kind of elegant theoretical property…”\nBut here’s the catch:\n“…the reality is that we can’t work with a posterior distribution. A high-dimensional probability distribution is a kind of meaningless thing. It’s this abstraction that we can’t interact with.”\nSo, how do we extract useful insights?\n\nFrom Posteriors to Expectations\nIn Bayesian inference, once we have our model and some data, the goal is to compute the posterior distribution, which combines our prior beliefs and the information from the data. This is usually written as:\n\\(\\pi(q \\mid D) \\propto \\pi(D \\mid q) \\pi(q)\\)\nHere, q represents all the unknown quantities we are trying to learn. These could be parameters like growth rates, optimal temperatures, or bite rate. The space of all possible values that q could take is what we call the parameter space. In simple models, this space might be one or two dimensional. In more realistic models—like those describing mosquito traits and parasite development—it can easily become 10, 20, or even hundreds of dimensions.\nNow, suppose we want to estimate something from this posterior—say, the average value of one trait or the probability that it exceeds a certain threshold. In Bayesian statistics, this means we need to compute expectations, which take the form:\n\\(\\mathbb{E}_{\\pi}[f] = \\int dq \\, \\pi(q \\mid D) f(q)\\)\nThis is the central computation in Bayesian inference. But computing such integrals extremely hard in high dimensions because it does not just evaluate the integrand, it aggregates it over volumns.\nImagine covering a 1D space (a line) with intervals.\n\n\n\n\n\nIn 2D, covering a square requires 9 tiles—one in the center and 8 around.\n\n\n\n\n\nIn 3D, a cube is surrounded by 26 others.\n\n\n\n\n\nAs dimensions increase, this “surrounding” effect grows rapidly. The volume of the space explodes outward, and the small region near the peak of our distribution (where we expect to learn the most) becomes a tiny fraction of the whole space.\nThis is a core problem. Even if we know where the posterior is highest (its “peak”), most of the probability mass lies in a weird, thin shell around it, not directly at the center. And trying to integrate over this complex shape with regular grid-based methods (like the ones we learn in calculus) just isn’t feasible when the dimension goes beyond 3 or 4.\nSo, to actually compute expectations in high-dimensional parameter spaces, we need smarter tools. This is where Monte Carlo method step in, and eventually, Markov Chain Monte Carlo come into play."
  },
  {
    "objectID": "mcmc.html#monte-carlo-sampling-instead-of-solving",
    "href": "mcmc.html#monte-carlo-sampling-instead-of-solving",
    "title": "MCMC Tutorial",
    "section": "Monte Carlo: Sampling Instead of Solving",
    "text": "Monte Carlo: Sampling Instead of Solving\nSo far, we’ve learned that Bayesian inference boils down to computing an expectation: an integral over a high-dimensional parameter space. But as we saw, volume in high dimensions behaves oddly—making that integral nearly impossible to solve with traditional methods like grid search or numeric quadrature. The regions that matter most are small and hard to find.\nThis is where Monte Carlo methods step in. Rather than trying to compute the integral directly, Monte Carlo flips the problem: it draws random samples from the posterior distribution, and then approximates the expectation by averaging over those samples.\nThink of it like this: imagine trying to understand how students perform in a large university, but instead of surveying every single student, you randomly sample students from the most populated classes—because that’s where most of the action happens. Similarly, Monte Carlo sampling draws points from areas where the posterior distribution places the most weight. These areas, known as the typical set, are where most of the useful information lives. So instead of wasting effort sampling from the outskirts, Monte Carlo methods focus where it counts.\nMathematically, if we draw N independent samples \\(q_1, q_2, \\ldots, q_N\\) from the posterior \\(\\pi(q \\mid D)\\), the Monte Carlo estimator is simply:\n\\[\\frac{1}{N} \\sum_{n=1}^{N} f(q_n) \\sim \\mathcal{N}\\left(\\mathbb{E}[f], \\frac{\\mathrm{Var}[f]}{N} \\right)\\]\nBut there’s a challenge.\nSampling from a complex posterior is not straightforward. In order to draw the sample, we need to know where the typical set is. They are the same problem. All I have done is recasting the problem in a different manner. The typical set is a thin, hard-to-find slice of the full space. If our samples miss it, then the estimate is wrong. Monte Carlo tells us what to do, but not how to do it.\nAnd that’s where Markov chains come in."
  },
  {
    "objectID": "mcmc.html#markov-chains-stepping-through-the-posterior",
    "href": "mcmc.html#markov-chains-stepping-through-the-posterior",
    "title": "MCMC Tutorial",
    "section": "Markov Chains: Stepping Through the Posterior",
    "text": "Markov Chains: Stepping Through the Posterior\nInstead of sampling independently, we construct a sequence of correlated samples. We start at one point \\(q{\\prime}\\) in parameter space and generate the next point q using a transition rule, or what’s formally called a Markov transition kernel, written as:\n\\[T(q \\mid q{\\prime})\\]\nThis transition rule defines the probability of jumping from one state to another. We repeat this process—step by step—generating a chain of points that slowly “wanders” through the parameter space. You can think of it as taking a random walk.\nThis alone doesn’t help much. But here’s the key insight: if we engineer this transition kernel \\(T(q \\mid q{\\prime})\\) to preserve the posterior distribution, then something powerful happens.\nFormally, the stationary distribution of the chain becomes our target posterior:\n\\[\\pi(q) = \\int \\pi(q{\\prime}) \\, T(q \\mid q{\\prime}) \\, dq{\\prime}\\]\nThis equation says: if we draw enough samples using a well-designed Markov transition, the resulting distribution of the chain will match the posterior we care about. Even though the individual samples are correlated, they still reflect the true structure of the target distribution.\n\n\n\nMarkov transition preserves target distribution that natually concentrates towards the typical set\n\n\nSo, Markov chains let us do the impossible: sample from complex posteriors without needing a full map of the space. Instead, we let the chain guide us, one probabilistic step at a time.\n\nWe combine this idea with Monte Carlo, and it leads us to the powerhouse technique known as Markov Chain Monte Carlo (MCMC)."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Final Project",
    "section": "",
    "text": "In this project, we aim to recreate a specific component of the analysis from Johnson et al. (2015), which investigates how temperature influences the transmission potential of malaria through its effect on various mosquito and parasite traits. Rather than reproducing the full reproductive number \\(R_0\\), we focus on a single temperature-sensitive trait — parasite development rate (PDR) and mosquito mortality — to explore how Bayesian inference can quantify uncertainty in that trait’s temperature response. The data for this analysis come from the VectorByte platform, which provides curated temperature-dependent trait data relevant to vector-borne diseases. By implementing and visualizing this subset of the model, we illustrate the impact of trait uncertainty on broader disease transmission dynamics, using methods and approaches aligned with those described in the original paper."
  },
  {
    "objectID": "conclusions.html",
    "href": "conclusions.html",
    "title": "Conclusions",
    "section": "",
    "text": "We modeled four temperature-sensitive traits critical to malaria transmission:\n\n\n\n\n\n\n\n\n\n\n\nTrait\nModel Used\nData Quality\nOptimal Temperature (Topt)\nPeak Value Estimate\nNotes\n\n\n\n\nSurvival Rate\nQuadratic\n10 pts\n~24.5°C\n~0.77 proportion\nJuvenile stage; reliable fit\n\n\nMDR\nBrière\n10 pts\n~8.9–13°C (T0), ~38°C (Tm)\nc ≈ 5.6e-5\nInverted development time\n\n\nOocyst Prevalence\nQuadratic\nModerate\n~24.5°C\n~0.75–0.85\nProportional data\n\n\nOocyst Intensity\nQuadratic (log-scale)\nModerate\n~24°C–25°C\nCount scale ~1–15\nLog-normal model fit\n\n\n\n\n\n\n\nTrace Plots confirmed good convergence for all traits. Chains were well-mixed and overlapped, indicating reliable sampling.\nPosterior Predictive Plots:\n\nSurvival and MDR showed well-defined unimodal curves.\nOocyst traits displayed higher variance but retained biologically meaningful peaks.\n\n95% Credible Intervals:\n\nNarrow for survival due to low noise.\nWider for oocyst traits, reflecting greater uncertainty in measurement and sample variability.\n\n\n\n\n\nWe implemented weakly informative priors where appropriate:\n\nFor survival, a prior centered at 0.85 aligned with observed data and biological expectations.\nFor rate-based models like MDR, we used domain-informed constraints on T0 and Tm to prevent unrealistic values.\nThese priors stabilized MCMC behavior without dominating the likelihood, making the results more robust and biologically interpretable.\n\n\n\n\n\nThermal Optimum: All traits peaked around 24–25°C, reinforcing this zone as critical for vector competence and transmission efficiency.\nThermal Limits: MDR and intensity rapidly declined outside this range, signaling increased developmental stress.\nUncertainty Focus: Traits like oocyst intensity showed broader credible bands, especially at low and high temperature extremes — highlighting where future experiments could reduce uncertainty.\n\n\n\n\nThis project successfully replicated the modeling framework of Johnson et al. (2015), validating it across both synthetic and real trait data from Anopheles gambiae and Plasmodium falciparum. Using Bayesian inference and JAGS, we not only estimated trait performance curves, but quantified uncertainty — a vital step for downstream applications like predicting malaria risk via R₀.\nNext Steps could include:\n\nPropagating posterior draws into R₀ calculations\nExpanding to additional traits like biting rate or transmission probability\nValidating model generalizability across new datasets or vector-parasite pairs\n\nThis work underscores how even sparse biological data, when combined with sound modeling and Bayesian thinking, can yield actionable insights in infectious disease ecology."
  },
  {
    "objectID": "conclusions.html#summary-of-modeled-traits",
    "href": "conclusions.html#summary-of-modeled-traits",
    "title": "Conclusions",
    "section": "",
    "text": "We modeled four temperature-sensitive traits critical to malaria transmission:\n\n\n\n\n\n\n\n\n\n\n\nTrait\nModel Used\nData Quality\nOptimal Temperature (Topt)\nPeak Value Estimate\nNotes\n\n\n\n\nSurvival Rate\nQuadratic\n10 pts\n~24.5°C\n~0.77 proportion\nJuvenile stage; reliable fit\n\n\nMDR\nBrière\n10 pts\n~8.9–13°C (T0), ~38°C (Tm)\nc ≈ 5.6e-5\nInverted development time\n\n\nOocyst Prevalence\nQuadratic\nModerate\n~24.5°C\n~0.75–0.85\nProportional data\n\n\nOocyst Intensity\nQuadratic (log-scale)\nModerate\n~24°C–25°C\nCount scale ~1–15\nLog-normal model fit"
  },
  {
    "objectID": "conclusions.html#plot-interpretation-and-uncertainty",
    "href": "conclusions.html#plot-interpretation-and-uncertainty",
    "title": "Conclusions",
    "section": "",
    "text": "Trace Plots confirmed good convergence for all traits. Chains were well-mixed and overlapped, indicating reliable sampling.\nPosterior Predictive Plots:\n\nSurvival and MDR showed well-defined unimodal curves.\nOocyst traits displayed higher variance but retained biologically meaningful peaks.\n\n95% Credible Intervals:\n\nNarrow for survival due to low noise.\nWider for oocyst traits, reflecting greater uncertainty in measurement and sample variability."
  },
  {
    "objectID": "conclusions.html#impact-of-priors",
    "href": "conclusions.html#impact-of-priors",
    "title": "Conclusions",
    "section": "",
    "text": "We implemented weakly informative priors where appropriate:\n\nFor survival, a prior centered at 0.85 aligned with observed data and biological expectations.\nFor rate-based models like MDR, we used domain-informed constraints on T0 and Tm to prevent unrealistic values.\nThese priors stabilized MCMC behavior without dominating the likelihood, making the results more robust and biologically interpretable."
  },
  {
    "objectID": "conclusions.html#biological-insights",
    "href": "conclusions.html#biological-insights",
    "title": "Conclusions",
    "section": "",
    "text": "Thermal Optimum: All traits peaked around 24–25°C, reinforcing this zone as critical for vector competence and transmission efficiency.\nThermal Limits: MDR and intensity rapidly declined outside this range, signaling increased developmental stress.\nUncertainty Focus: Traits like oocyst intensity showed broader credible bands, especially at low and high temperature extremes — highlighting where future experiments could reduce uncertainty."
  },
  {
    "objectID": "conclusions.html#final-thoughts",
    "href": "conclusions.html#final-thoughts",
    "title": "Conclusions",
    "section": "",
    "text": "This project successfully replicated the modeling framework of Johnson et al. (2015), validating it across both synthetic and real trait data from Anopheles gambiae and Plasmodium falciparum. Using Bayesian inference and JAGS, we not only estimated trait performance curves, but quantified uncertainty — a vital step for downstream applications like predicting malaria risk via R₀.\nNext Steps could include:\n\nPropagating posterior draws into R₀ calculations\nExpanding to additional traits like biting rate or transmission probability\nValidating model generalizability across new datasets or vector-parasite pairs\n\nThis work underscores how even sparse biological data, when combined with sound modeling and Bayesian thinking, can yield actionable insights in infectious disease ecology."
  }
]